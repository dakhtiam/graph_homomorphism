{"cells":[{"cell_type":"markdown","metadata":{"id":"k-Jk756iXx2q"},"source":["# Experiments"]},{"cell_type":"markdown","metadata":{"id":"km8hHzIAXx22"},"source":["### imports"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":2533,"status":"ok","timestamp":1653662064343,"user":{"displayName":"Tamir Hemo","userId":"01253531569268226149"},"user_tz":420},"id":"qwDoI-tqXx22"},"outputs":[],"source":["import torch\n","from torch_geometric.data import Data\n","from torch_geometric.transforms import BaseTransform\n","from torch_geometric.datasets import TUDataset, ZINC\n","from ogb.graphproppred import PygGraphPropPredDataset\n","import torch_geometric.utils as uts\n","from torch_geometric.utils import remove_self_loops, to_undirected\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import itertools\n","from tqdm import tqdm"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":4141,"status":"ok","timestamp":1653662068479,"user":{"displayName":"Tamir Hemo","userId":"01253531569268226149"},"user_tz":420},"id":"R81qPkC1Xx23"},"outputs":[],"source":["# Graph utilities\n","import networkx as nx\n","import graph_encoding.encoding as encoding \n"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1653662068480,"user":{"displayName":"Tamir Hemo","userId":"01253531569268226149"},"user_tz":420},"id":"NIagj4S8gKej"},"outputs":[],"source":["from importlib import reload \n","\n","encoding = reload(encoding)\n"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":308,"status":"ok","timestamp":1653663402199,"user":{"displayName":"Tamir Hemo","userId":"01253531569268226149"},"user_tz":420},"id":"PmQvlE-_BNRx"},"outputs":[],"source":["# sklearn imports\n","from sklearn.pipeline import make_pipeline\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.svm import SVC\n","from sklearn.ensemble import RandomForestClassifier\n","\n","from sklearn.model_selection import cross_val_score, StratifiedKFold\n","from sklearn.model_selection import train_test_split\n","from sklearn.decomposition import PCA"]},{"cell_type":"markdown","metadata":{"id":"Aya8Voe_Xx24"},"source":["## Helper functions"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":280,"status":"ok","timestamp":1653663405036,"user":{"displayName":"Tamir Hemo","userId":"01253531569268226149"},"user_tz":420},"id":"VJ436CZ0Xx25"},"outputs":[],"source":["# set up embedding \n","\n","def add_testgraphs(encoded_data, limit_vertex = None,\n","            n_trees = 4, limit_trees = 10000,\n","            n_cycles = 4,limit_cycles = 10000, \n","            n_cliques = 4, limit_cliques = 100):\n","  \n","    encoded_data.clear_all_testgraphs()\n","    encoded_data.add_single_vertex(limit = limit_vertex)\n","    encoded_data.add_trees(stop = n_trees, limit = limit_trees)\n","    encoded_data.add_cycles(stop = n_cycles, limit = limit_cycles)\n","    encoded_data.add_cliques(stop = n_cliques, limit = limit_cliques)\n","  \n","\n","  "]},{"cell_type":"markdown","metadata":{"id":"tEaXnTRIBTTr"},"source":["helper functions for model fitting:"]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":393,"status":"ok","timestamp":1653663718946,"user":{"displayName":"Tamir Hemo","userId":"01253531569268226149"},"user_tz":420},"id":"s3shAJP2BDjO"},"outputs":[],"source":["# calculate fit and plot scores\n","\n","def calculate_single_split_score(clf, X, y, cv_num, random_state,\n","                                 scoring='accuracy', test_size=0.25):\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, \n","                                      test_size=test_size, random_state=random_state)\n","    clf.fit(X_train, y_train)\n","\n","    train_score = clf.score(X_train, y_train)\n","    test_score = clf.score(X_test, y_test)\n","\n","    return {'train_score' : train_score,'test_score': test_score}\n","    \n","\n","def calculate_cv_scores(clf, X, y, cv_num, scoring='accuracy'):\n","  cv = cv_num\n","  scores = cross_val_score(clf, X, y, cv=cv_num, scoring = scoring)\n","\n","  return scores\n","\n","def plot_cv_scores(scores, clf_name, cv_num):\n","  width = 0.35\n","  labels = [f'G{n}' for n in range(1,cv_num+1)]\n","  fig = plt.figure()\n","  ax = fig.add_subplot()\n","  ax.bar(labels, scores, width)\n","  ax.set_ylabel('Scores')\n","  ax.set_title('Cross validation scores for '+clf_name)\n","  plt.axhline(y = scores.mean(), c = 'black', linewidth = 0.7, \n","            label = f'Err = {scores.mean():.2f}' + u\"\\u00B1\" + f'{scores.std():.2f}')\n","  ax.legend()\n","\n","  plt.show()\n","  print(f'Validation error = {scores.mean():.2f}' + u\"\\u00B1\" + f'{scores.std():.2f}')"]},{"cell_type":"markdown","metadata":{"id":"2w797b51Xx26"},"source":["## Experiments: graph classification tasks"]},{"cell_type":"markdown","metadata":{"id":"3spOdtbJYPY5"},"source":["### First experiment: MUTAG:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":317,"status":"ok","timestamp":1653450281826,"user":{"displayName":"Tamir Hemo","userId":"01253531569268226149"},"user_tz":420},"id":"p1ZIaMxrYRXz","outputId":"5e46e3fe-a722-48a7-bea0-d410140c6fc4"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Dataset: MUTAG(188):\n","====================\n","Number of graphs: 188\n","Number of features: 7\n","Number of classes: 2\n","\n","Data(edge_index=[2, 38], x=[17, 7], edge_attr=[38, 4], y=[1])\n","=============================================================\n"]}],"source":["# load the data:\n","\n","dataset = TUDataset(root='data/TUDataset', name='MUTAG')\n","\n","print()\n","print(f'Dataset: {dataset}:')\n","print('====================')\n","print(f'Number of graphs: {len(dataset)}')\n","print(f'Number of features: {dataset.num_features}')\n","print(f'Number of classes: {dataset.num_classes}')\n","\n","data = dataset[0]  # Get the first graph object.\n","\n","print()\n","print(data)\n","print('=============================================================')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":322,"status":"ok","timestamp":1653450285474,"user":{"displayName":"Tamir Hemo","userId":"01253531569268226149"},"user_tz":420},"id":"v0Hb7i5mY6zv","outputId":"cae1b57e-fb0b-48d1-8450-9f083fff8b73"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 188/188 [00:00<00:00, 2890.32it/s]\n"]}],"source":["# pre-processing MUTAG\n","Encoded_Dataset = [encode(data) for data in tqdm(dataset)]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2397,"status":"ok","timestamp":1653441033130,"user":{"displayName":"Tamir Hemo","userId":"01253531569268226149"},"user_tz":420},"id":"UYWtPzHhY4R8","outputId":"8ea10e1d-e52e-4abf-9c25-3b571a665d10"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 188/188 [00:01<00:00, 97.29it/s]\n"]}],"source":["# get representation MUTAG\n","# labels\n","y = np.array([data.pyg_graph().y.detach().numpy() for data in Encoded_Dataset])\n","# vectors\n","X = np.array([data.ghc_encoder(format = 'numpy')  for data in tqdm(Encoded_Dataset)])\n","#%timeit Encoded_Dataset[0].ghc_encoder(format = 'numpy')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LiV0FsztxAr7"},"outputs":[],"source":["y = y.reshape(188)"]},{"cell_type":"markdown","metadata":{"id":"9c5_E0UGt_40"},"source":["### Experiment: \"ogbg-molhiv\" "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WsSE3dO8uAcE"},"outputs":[],"source":["# setup the provided node encoder\n","from ogb.graphproppred.mol_encoder import AtomEncoder, BondEncoder\n","emb_dim = 10\n","atom_encoder = AtomEncoder(emb_dim)\n","bond_encoder = BondEncoder(emb_dim)\n","\n","class atom_transform(BaseTransform):\n","  def __call__(self, data):\n","    newdata = data.clone()\n","    newdata.x = atom_encoder(data.x)\n","    return newdata\n","\n","transform = atom_transform()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":520,"status":"ok","timestamp":1653608376265,"user":{"displayName":"Tamir Hemo","userId":"01253531569268226149"},"user_tz":420},"id":"RGXQHRdruWE7","outputId":"e875f362-5b78-4579-a5ee-3af6d925f8e3"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Dataset: PygGraphPropPredDataset(41127):\n","====================\n","Number of graphs: 41127\n","Number of features: 10\n","Number of classes: 2\n","\n","Data(edge_index=[2, 38], edge_attr=[38, 3], x=[18, 10], y=[1, 1], num_nodes=18)\n","=============================================================\n"]}],"source":["# load the data \n","dataset = PygGraphPropPredDataset(name = \"ogbg-molhiv\", root = 'dataset/', transform = transform)\n","\n","print()\n","print(f'Dataset: {dataset}:')\n","print('====================')\n","print(f'Number of graphs: {len(dataset)}')\n","print(f'Number of features: {dataset.num_features}')\n","print(f'Number of classes: {dataset.num_classes}')\n","\n","data = dataset[7]  # Get the first graph object.\n","\n","print()\n","print(data)\n","print('=============================================================')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QKN0sSF3m3lp"},"outputs":[],"source":["encoded_dataset = [encoding.grandEmbedding(data) for data in tqdm(dataset)]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yFcw6Ccv1liG"},"outputs":[],"source":["def single_graph_data(i, encoder, file_name,\n","                      n_cliques, n_cycles, n_trees):\n","  add_graphs = lambda x: add_testgraphs(encoded_data = x,                                           n_trees= n_trees, limit_trees= 10000,                                              n_cycles=n_cycles, limit_cycles = 10000,\n","                                      n_cliques= n_cliques, limit_cliques=100)\n","  add_to_Dataset = [add_graphs(data) for data in tqdm(encoded_dataset)]\n","  # labels\n","  y = np.array([data.pyg_graph().y[0,0].detach().numpy() for data in tqdm(encoded_dataset)])\n","  #vectors\n","  X = np.array([encoder(data)  for data in tqdm(encoded_dataset)])\n","  nums = np.array([n_cliques, n_cycles, n_trees])\n","  np.save(file_name +f'{i}_X.npy', X )\n","  np.save(file_name + f'{i}_y.npy', y )\n","  np.save(file_name +f'{i}_nums.npy', nums)\n","\n","\n","def gather_graph_data(encoder, file_name, cliques_limit = 5, \n","                      cycles_limit = 6, trees_limit = 6):\n","  i = 0\n","  for n_cliques in range(4,cliques_limit):\n","    for n_cycles in range(3,cycles_limit):\n","        for n_trees in range(2, trees_limit):\n","\n","          add_graphs = lambda x: add_testgraphs(encoded_data = x, \n","                                                n_trees= n_trees, limit_trees= 10000,\n","                                                n_cycles=n_cycles, limit_cycles = 10000,\n","                                                n_cliques= n_cliques, limit_cliques=100)\n","          add_to_Dataset = [add_graphs(data) for data in tqdm(encoded_dataset)]\n","          # labels\n","          y = np.array([data.pyg_graph().y[0,0].detach().numpy() for data in tqdm(encoded_dataset)])\n","          #vectors\n","          X = np.array([encoder(data)  for data in tqdm(encoded_dataset)])\n","          nums = np.array([n_cliques, n_cycles, n_trees])\n","          np.save(file_name +f'{i}_X.npy', X )\n","          np.save(file_name + f'{i}_y.npy', y )\n","          np.save(file_name +f'{i}_nums.npy', nums)\n","          i+=1   \n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QkAjMtdE27p5"},"outputs":[],"source":["# GHC:\n","file_name = 'Experiments/ogbg-molhiv/GHC_encoded_data/experiment_'\n","encdoer = lambda x: x.ghc_encoder(format = 'numpy')\n","gather_graph_data(encdoer, file_name)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DFZV6QW03cmh"},"outputs":[],"source":["# GHC with augmentation:\n","file_name = 'Experiments/ogbg-molhiv/ghc_aug/experiment_'\n","ghc = lambda x: x.ghc_encoder(format = 'numpy')\n","num_enc = lambda x: x.num_encoder(format = 'numpy')\n","encoder = lambda x: np.concatenate((ghc(x),num_enc(x)), axis = 0)\n","gather_graph_data(encdoer, file_name)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":418701,"status":"ok","timestamp":1653609312443,"user":{"displayName":"Tamir Hemo","userId":"01253531569268226149"},"user_tz":420},"id":"pfDqGea6thqx","outputId":"50bde91e-34f4-40c7-b1d0-400f2b4ee39d"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 41127/41127 [00:02<00:00, 16755.95it/s]\n","100%|██████████| 41127/41127 [00:00<00:00, 46463.91it/s]\n","100%|██████████| 41127/41127 [06:54<00:00, 99.15it/s]\n"]}],"source":["# Lagrangian with augmentation:\n","file_name = 'Experiments/ogbg-molhiv/lagrangian_aug/experiment_'\n","raw_encoder = lambda x: x.lagrangian_encoder(format = 'numpy')\n","num_enc = lambda x: x.num_encoder(format = 'numpy')\n","encoder = lambda x: np.concatenate((raw_encoder(x),num_enc(x)), axis = 0)\n","single_graph_data(800, encoder, file_name,\n","                  n_cliques = 4, n_cycles = 5, n_trees = 2)\n","#gather_graph_data(encdoer, file_name)"]},{"cell_type":"markdown","metadata":{"id":"wInutd_WYYq0"},"source":["#### Evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hjDuViXjkBwm"},"outputs":[],"source":["def set_up_experiment(X_train, y_train, X_valid, y_valid):\n","    C_array = [10**3, 10**2, 10** 1, 10**0, 10**-1, 10**-2, 10**-3]\n","\n","    max_score = 0\n","    C_max = 0\n","    for C in C_array:\n","        clf = make_pipeline(StandardScaler(), SVC(kernel='rbf', C = 1, probability = True, random_state=42))\n","        # fit model\n","        clf.fit(X_train, y_train)\n","        # Calculate predictions \n","        y_valid_pred = clf.predict_proba(X_valid)\n","\n","        y_pred_valid = y_valid_pred[:,1].reshape(4113,1)\n","        y_true_valid = y_valid.reshape(4113,1)\n","\n","        input_valid_dict = {'y_true': y_true_valid, 'y_pred': y_pred_valid}\n","        valid_score = evaluator.eval(input_valid_dict)['rocauc']\n","\n","        if valid_score > max_score:\n","            max_score = valid_score\n","            C_max = C\n","        return {'max_score': max_score, 'C_max' : C_max}"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":237,"status":"ok","timestamp":1653609333053,"user":{"displayName":"Tamir Hemo","userId":"01253531569268226149"},"user_tz":420},"id":"58EJk3rDa9JB","outputId":"e1fef122-f49d-4332-a5bb-5fe51abaddb2"},"outputs":[{"name":"stdout","output_type":"stream","text":["==== Expected input format of Evaluator for ogbg-molhiv\n","{'y_true': y_true, 'y_pred': y_pred}\n","- y_true: numpy ndarray or torch tensor of shape (num_graph, num_task)\n","- y_pred: numpy ndarray or torch tensor of shape (num_graph, num_task)\n","where y_pred stores score values (for computing AUC score),\n","num_task is 1, and each row corresponds to one graph.\n","nan values in y_true are ignored during evaluation.\n","\n","==== Expected output format of Evaluator for ogbg-molhiv\n","{'rocauc': rocauc}\n","- rocauc (float): ROC-AUC score averaged across 1 task(s)\n","\n"]}],"source":["from ogb.graphproppred import Evaluator\n","\n","evaluator = Evaluator(name = 'ogbg-molhiv')\n","print(evaluator.expected_input_format) \n","print(evaluator.expected_output_format)  "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q0bHgBJ9Yc6s"},"outputs":[],"source":["#usual GHC\n","X_list = [np.load(f'Experiments/ogbg-molhiv/GHC_encoded_data/experiment_{i}_X.npy') for i in range(12)]\n","y_list = [np.load(f'Experiments/ogbg-molhiv/GHC_encoded_data/experiment_{i}_y.npy') for i in range(12)]\n","nums_list = [np.load(f'Experiments/ogbg-molhiv/GHC_encoded_data/experiment_{i}_nums.npy') for i in range(12)]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gbId-M4ecvrz"},"outputs":[],"source":["# GHC augmented\n","X_list = [np.load(f'Experiments/ogbg-molhiv/ghc_aug/experiment_{i}_X.npy') for i in range(12)]\n","y_list = [np.load(f'Experiments/ogbg-molhiv/ghc_aug/experiment_{i}_y.npy') for i in range(12)]\n","nums_list = [np.load(f'Experiments/ogbg-molhiv/ghc_aug/experiment_{i}_nums.npy') for i in range(12)]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":222,"status":"ok","timestamp":1653603534445,"user":{"displayName":"Tamir Hemo","userId":"01253531569268226149"},"user_tz":420},"id":"fakdpNc_BjGF","outputId":"fbf1ff9b-3841-47b4-e3c6-ecb766750764"},"outputs":[{"data":{"text/plain":["((41127, 11), 12, 12)"]},"execution_count":98,"metadata":{},"output_type":"execute_result"}],"source":["X_list[0].shape, len(y_list), len(nums_list)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"keCywrCadNz_"},"outputs":[],"source":["# Using the given train-test split\n","\n","split_idx = dataset.get_idx_split()\n","\n","train_idx = split_idx[\"train\"]\n","valid_idx = split_idx[\"valid\"]\n","test_idx  = split_idx[\"test\"]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":231,"status":"ok","timestamp":1653603540434,"user":{"displayName":"Tamir Hemo","userId":"01253531569268226149"},"user_tz":420},"id":"R-rHns97dW2x","outputId":"aa198bd6-5e9c-4c55-ac12-914229b0e68c"},"outputs":[{"data":{"text/plain":["[(41127, 11),\n"," (41127, 22),\n"," (41127, 33),\n"," (41127, 55),\n"," (41127, 22),\n"," (41127, 33),\n"," (41127, 44),\n"," (41127, 66),\n"," (41127, 33),\n"," (41127, 44),\n"," (41127, 55),\n"," (41127, 77)]"]},"execution_count":100,"metadata":{},"output_type":"execute_result"}],"source":["list(map(lambda x: x.shape, X_list))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":241,"status":"ok","timestamp":1653603543966,"user":{"displayName":"Tamir Hemo","userId":"01253531569268226149"},"user_tz":420},"id":"nbNgFTAXhvbc","outputId":"8984b955-7086-4880-ebb5-881c119cf7b7"},"outputs":[{"data":{"text/plain":["array([4, 5, 5])"]},"execution_count":101,"metadata":{},"output_type":"execute_result"}],"source":["nums_list[11]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MYHp8SKFiJyX"},"outputs":[],"source":["def calculate_score_SVM(i):\n","  X = X_list[i]\n","  y = y_list[i]\n","\n","  X_train , y_train = X[train_idx], y[train_idx]\n","  X_valid , y_valid = X[valid_idx], y[valid_idx]\n","  X_test , y_test = X[test_idx], y[test_idx]\n","\n","  result_dict = set_up_experiment(X_train, y_train, X_valid, y_valid)\n","\n","  best_val_score = result_dict['max_score']\n","  C_max = result_dict['C_max']\n","\n","  clf = make_pipeline(StandardScaler(), SVC(kernel='rbf', C = C_max, probability = True, random_state=42))\n","  # fit model\n","  clf.fit(X_train, y_train)\n","\n","  # calculate test auroc\n","  y_test_pred = clf.predict_proba(X_test)\n","  y_pred_test = y_test_pred[:,1].reshape(4113,1)\n","  y_true_test = y_test.reshape(4113,1)\n","\n","  input_test_dict = {'y_true': y_true_test, 'y_pred': y_pred_test}\n","  test_score = evaluator.eval(input_test_dict)['rocauc']\n","\n","  # calculate train auroc\n","  y_train_pred = clf.predict_proba(X_train)\n","  y_pred_train = y_train_pred[:,1].reshape(32901,1)\n","  y_true_train = y_train.reshape(32901,1)\n","  \n","  input_train_dict = {'y_true': y_true_train, 'y_pred': y_pred_train}\n","  train_score = evaluator.eval(input_train_dict)['rocauc']\n","\n","  return [train_score, test_score, best_val_score, C_max]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13844751,"status":"ok","timestamp":1653553917500,"user":{"displayName":"Tamir Hemo","userId":"01253531569268226149"},"user_tz":420},"id":"p9t8Z7nqp5jK","outputId":"e0aa3957-d490-4ea6-ef21-b117d39175d9"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 12/12 [3:50:44<00:00, 1153.69s/it]\n"]}],"source":["for i in tqdm(range(12)): \n","  svm_data = calculate_score_SVM(i)\n","  svm_data_array = np.array(svm_data)\n","  np.save(f'Experiments/ogbg-molhiv/svm_data_{i}.npy', svm_data_array)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I4Lx8T2-zsqZ"},"outputs":[],"source":["# load single experiment Lag\n","X = np.load(f'Experiments/ogbg-molhiv/lagrangian_aug/experiment_800_X.npy')\n","y = np.load(f'Experiments/ogbg-molhiv/lagrangian_aug/experiment_800_y.npy')\n","nums_list = np.load(f'Experiments/ogbg-molhiv/lagrangian_aug/experiment_800_nums.npy')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":235,"status":"ok","timestamp":1653609532922,"user":{"displayName":"Tamir Hemo","userId":"01253531569268226149"},"user_tz":420},"id":"-3id-scszvKE","outputId":"1dea73c5-ba33-4992-fedb-db8071fa3e66"},"outputs":[{"data":{"text/plain":["((41127, 33), (41127,), array([4, 5, 2]))"]},"execution_count":143,"metadata":{},"output_type":"execute_result"}],"source":["X.shape, y.shape, nums_list"]},{"cell_type":"markdown","metadata":{"id":"kJuVe7C3B14f"},"source":["#### Random forest eval:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i_07D83zX1zK"},"outputs":[],"source":["# try PCA before evaluation\n","from sklearn.decomposition import PCA, IncrementalPCA"]},{"cell_type":"markdown","metadata":{"id":"72CeonggB41G"},"source":["One random forest measuremnt:\n","\n","> Indented block\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sDnU2a9MZkHi"},"outputs":[],"source":["def molhiv_calculate_score_single_forest(X, y):\n","  X_train , y_train = X[train_idx], y[train_idx]\n","  X_valid , y_valid = X[valid_idx], y[valid_idx]\n","  X_test , y_test = X[test_idx], y[test_idx]\n","\n","  # preprocess pca\n","  if i > 1:\n","    pca = PCA(n_components = 20)\n","  else:\n","    pca = PCA()\n","  pca.fit(X_train, y_train)\n","\n","  X_train_new = pca.transform(X_train)\n","  X_valid_new = pca.transform(X_valid)\n","  X_test_new = pca.transform(X_test)\n","\n","  clf = make_pipeline(StandardScaler(), RandomForestClassifier(random_state=42))\n","  # fit model\n","  clf.fit(X_train_new, y_train)\n","  \n","  # calculate test auroc\n","  y_test_pred = clf.predict_proba(X_test_new)\n","  y_pred_test = y_test_pred[:,1].reshape(4113,1)\n","  y_true_test = y_test.reshape(4113,1)\n","\n","  input_test_dict = {'y_true': y_true_test, 'y_pred': y_pred_test}\n","  test_score = evaluator.eval(input_test_dict)['rocauc']\n","\n","  # calculate valid auroc\n","  y_valid_pred = clf.predict_proba(X_valid_new)\n","  y_pred_valid = y_valid_pred[:,1].reshape(4113,1)\n","  y_true_valid = y_valid.reshape(4113,1)\n","\n","  input_valid_dict = {'y_true': y_true_valid, 'y_pred': y_pred_valid}\n","  valid_score = evaluator.eval(input_valid_dict)['rocauc']\n","\n","  # calculate train auroc\n","  y_train_pred = clf.predict_proba(X_train_new)\n","  y_pred_train = y_train_pred[:,1].reshape(32901,1)\n","  y_true_train = y_train.reshape(32901,1)\n","  \n","  input_train_dict = {'y_true': y_true_train, 'y_pred': y_pred_train}\n","  train_score = evaluator.eval(input_train_dict)['rocauc']\n","\n","  return [train_score, valid_score, test_score]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MzbVag_Wm5Nw"},"outputs":[],"source":["def molhiv_calculate_score_random_forest(i):\n","  X = X_list[i]\n","  y = y_list[i]\n","\n","  return molhiv_calculate_score_single_forest(X,y)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":263651,"status":"ok","timestamp":1653603924609,"user":{"displayName":"Tamir Hemo","userId":"01253531569268226149"},"user_tz":420},"id":"O9xeejtLnvGp","outputId":"624293e4-1804-4a15-b758-8c45993b1269"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 12/12 [04:23<00:00, 21.93s/it]\n"]}],"source":["# run random forest\n","for i in tqdm(range(12)): \n","  random_forest_data = molhiv_calculate_score_random_forest(i)\n","  random_forest_data_array = np.array(random_forest_data)\n","  np.save(f'Experiments/ogbg-molhiv/random_forest_scores_{i}.npy', random_forest_data_array)"]},{"cell_type":"code","execution_count":82,"metadata":{},"outputs":[{"data":{"text/plain":["[array([0.99999981, 0.74252882]),\n"," array([1.        , 0.74369629]),\n"," array([1.        , 0.73329632]),\n"," array([1.        , 0.73594604]),\n"," array([0.99999956, 0.73366326]),\n"," array([1.        , 0.74253752]),\n"," array([1.        , 0.71936886]),\n"," array([1.        , 0.71889279]),\n"," array([0.99999924, 0.75866761]),\n"," array([0.99999999, 0.71003013]),\n"," array([1.        , 0.72188049]),\n"," array([1.        , 0.69132757])]"]},"execution_count":82,"metadata":{},"output_type":"execute_result"}],"source":["# load scores:\n","[np.load(f'Experiments/ogbg-molhiv/ghc_aug/random_forest_scores_{i}.npy') for i in range(12)]"]},{"cell_type":"code","execution_count":83,"metadata":{},"outputs":[{"data":{"text/plain":["[array([4, 3, 2]),\n"," array([4, 3, 3]),\n"," array([4, 3, 4]),\n"," array([4, 3, 5]),\n"," array([4, 4, 2]),\n"," array([4, 4, 3]),\n"," array([4, 4, 4]),\n"," array([4, 4, 5]),\n"," array([4, 5, 2]),\n"," array([4, 5, 3]),\n"," array([4, 5, 4]),\n"," array([4, 5, 5])]"]},"execution_count":83,"metadata":{},"output_type":"execute_result"}],"source":["[np.load(f'Experiments/ogbg-molhiv/ghc_aug/experiment_{i}_nums.npy') for i in range(12)]"]},{"cell_type":"markdown","metadata":{"id":"no-PM-vjN9v5"},"source":["### Experiment: NCI-1"]},{"cell_type":"code","execution_count":84,"metadata":{"executionInfo":{"elapsed":418,"status":"ok","timestamp":1653662103782,"user":{"displayName":"Tamir Hemo","userId":"01253531569268226149"},"user_tz":420},"id":"UEdSZUEAR52H"},"outputs":[],"source":["class nci1_transform(BaseTransform):\n","   def __call__(self, data):\n","     new_data = data.clone()\n","     w = torch.rand(37)\n","     new_data.x = torch.unsqueeze(torch.tensordot(data.x, w,  dims=([1], [0])),1)\n","     return new_data\n","     \n","transform = nci1_transform()\n"]},{"cell_type":"code","execution_count":85,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":310,"status":"ok","timestamp":1653665106170,"user":{"displayName":"Tamir Hemo","userId":"01253531569268226149"},"user_tz":420},"id":"WscK9lAQN_FA","outputId":"0b2b341d-9fc9-472c-f587-54d39f13f1fc"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Dataset: NCI1(4110):\n","====================\n","Number of graphs: 4110\n","Number of features: 1\n","Number of classes: 2\n","\n","Data(edge_index=[2, 42], x=[21, 1], y=[1])\n","=============================================================\n"]}],"source":["# load the data:\n","\n","dataset = TUDataset(root='data_local/TUDataset', name='NCI1', transform=transform)\n","\n","print()\n","print(f'Dataset: {dataset}:')\n","print('====================')\n","print(f'Number of graphs: {len(dataset)}')\n","print(f'Number of features: {dataset.num_features}')\n","print(f'Number of classes: {dataset.num_classes}')\n","\n","data = dataset[0]  # Get the first graph object.\n","\n","print()\n","print(data)\n","print('=============================================================')"]},{"cell_type":"code","execution_count":86,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":963,"status":"ok","timestamp":1653665110070,"user":{"displayName":"Tamir Hemo","userId":"01253531569268226149"},"user_tz":420},"id":"pfaF7RYLOKA0","outputId":"724d767a-ec46-4a48-e98b-d965cd04c9fe"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 4110/4110 [00:02<00:00, 1923.32it/s]\n"]}],"source":["encoded_dataset = [encoding.grandEmbedding(data) for data in tqdm(dataset)]"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":412,"status":"ok","timestamp":1653665112517,"user":{"displayName":"Tamir Hemo","userId":"01253531569268226149"},"user_tz":420},"id":"vnYJrdBEee40","outputId":"95fac072-591e-4c62-f62f-0c4442c06ea3"},"outputs":[{"data":{"text/plain":["tensor([0.1136])"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["encoded_dataset[0].pyg_graph().x[0]"]},{"cell_type":"code","execution_count":87,"metadata":{"executionInfo":{"elapsed":419,"status":"ok","timestamp":1653665115483,"user":{"displayName":"Tamir Hemo","userId":"01253531569268226149"},"user_tz":420},"id":"rTtuoR5d1_nm"},"outputs":[],"source":["def TU_graph_data(i, encoder, file_name,\n","                      n_cliques, n_cycles, n_trees):\n","  add_graphs = lambda x: add_testgraphs(encoded_data = x,                                           n_trees= n_trees, limit_trees= 10000,                                              n_cycles=n_cycles, limit_cycles = 10000,\n","                                      n_cliques= n_cliques, limit_cliques=100)\n","  add_to_Dataset = [add_graphs(data) for data in tqdm(encoded_dataset)]\n","  # labels\n","  y = np.array([data.pyg_graph().y.detach().numpy() for data in tqdm(encoded_dataset)])\n","  #vectors\n","  X = np.array([encoder(data)  for data in tqdm(encoded_dataset)])\n","  nums = np.array([n_cliques, n_cycles, n_trees])\n","  np.save(file_name +f'{i}_X.npy', X )\n","  np.save(file_name + f'{i}_y.npy', y )\n","  np.save(file_name +f'{i}_nums.npy', nums)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":805149,"status":"ok","timestamp":1653638722691,"user":{"displayName":"Tamir Hemo","userId":"01253531569268226149"},"user_tz":420},"id":"bMqQSd7w1K4I","outputId":"5fce26a7-cbd2-45d9-8ff1-c058e44e5174"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 4110/4110 [00:03<00:00, 1306.56it/s]\n","100%|██████████| 4110/4110 [00:00<00:00, 108540.31it/s]\n","100%|██████████| 4110/4110 [13:21<00:00,  5.13it/s]\n"]}],"source":["# ghc:\n","file_name = 'Experiments/NCI1/ghc/experiment_'\n","ghc_encoder = lambda x: x.ghc_encoder(format = 'numpy')\n","#num_enc = lambda x: x.num_encoder(format = 'numpy')\n","#encoder = lambda x: np.concatenate((raw_encoder(x),num_enc(x)), axis = 0)\n","TU_graph_data(800, ghc_encoder, file_name,\n","                  n_cliques = 6, n_cycles = 6, n_trees = 8)\n","#gather_graph_data(encdoer, file_name)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"bGUcNuessmB1","outputId":"0928ec4d-7ed3-4fac-8fe2-26a2b85f76ad"},"outputs":[],"source":["# Lagrangian gather data:\n","file_name = 'Experiments/NCI1/lagrangian_aug/experiment_'\n","pure_encoder = lambda x: x.lagrangian_encoder(format = 'numpy')\n","num_enc = lambda x: x.num_encoder(format = 'numpy')\n","encoder = lambda x: np.concatenate((pure_encoder(x),num_enc(x)), axis = 0)\n","\n","i = 0\n","for n_cliques in range(4,6):\n","  for n_cycles in range(3,10):\n","      for n_trees in range(2, 12):\n","        TU_graph_data(i, encoder, file_name,\n","                 n_cliques = n_cliques, n_cycles = n_cycles, n_trees = n_trees)\n","        i+=1"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":527,"status":"ok","timestamp":1653662584748,"user":{"displayName":"Tamir Hemo","userId":"01253531569268226149"},"user_tz":420},"id":"FOixdBB12KxA"},"outputs":[],"source":["# load single experiment Lag\n","def load_data_nci1(i, file_name):\n","  X = np.load(file_name+f'{i}_X.npy')\n","  y = np.load(file_name+f'{i}_y.npy').reshape(4110,)\n","  nums = np.load(file_name+f'{i}_nums.npy')\n","  return {'X': X, 'y': y, 'nums': nums}"]},{"cell_type":"code","execution_count":97,"metadata":{"executionInfo":{"elapsed":5024,"status":"ok","timestamp":1653663609888,"user":{"displayName":"Tamir Hemo","userId":"01253531569268226149"},"user_tz":420},"id":"S6gHJcBQ83Dr"},"outputs":[],"source":["# Lagrangian load data:\n","num_of_exps = 8\n","file_name = 'Experiments/NCI1/lagrangian_aug/experiment_'\n","X_list_lag = [load_data_nci1(i, file_name)['X'] for i in range(num_of_exps)]\n","y_list_lag = [load_data_nci1(i, file_name)['y'] for i in range(num_of_exps)]\n","nums_list_lag = [load_data_nci1(i, file_name)['nums'] for i in range(num_of_exps)]"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":331,"status":"ok","timestamp":1653663903574,"user":{"displayName":"Tamir Hemo","userId":"01253531569268226149"},"user_tz":420},"id":"lJViRH1K-NZv","outputId":"1b7ea92c-7a08-43e8-f3de-2a6beae0b09c"},"outputs":[{"data":{"text/plain":["((4110, 76), (4110,), (3,))"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["X_list_lag[1].shape, y_list_lag[0].shape, nums_list_lag[0].shape"]},{"cell_type":"code","execution_count":88,"metadata":{},"outputs":[],"source":["# ghc load data:\n","num_of_exps = 37\n","file_name = 'Experiments/NCI1/ghc/experiment_'\n","X_list_ghc = [load_data_nci1(i, file_name)['X'] for i in range(num_of_exps)]\n","y_list_ghc = [load_data_nci1(i, file_name)['y'] for i in range(num_of_exps)]\n","nums_list_ghc = [load_data_nci1(i, file_name)['nums'] for i in range(num_of_exps)]"]},{"cell_type":"code","execution_count":64,"metadata":{"executionInfo":{"elapsed":279,"status":"ok","timestamp":1653664839281,"user":{"displayName":"Tamir Hemo","userId":"01253531569268226149"},"user_tz":420},"id":"rgNlpZ0PGdAc"},"outputs":[],"source":["# lagrangian:\n","X_list = X_list_lag\n","y_list = y_list_lag\n","nums_list = nums_list_lag"]},{"cell_type":"code","execution_count":89,"metadata":{},"outputs":[],"source":["# ghc:\n","X_list = X_list_ghc\n","y_list = y_list_ghc\n","nums_list = nums_list_ghc"]},{"cell_type":"code","execution_count":65,"metadata":{},"outputs":[{"data":{"text/plain":["[array([4, 3, 2]),\n"," array([4, 3, 3]),\n"," array([4, 3, 4]),\n"," array([4, 3, 5]),\n"," array([4, 3, 6]),\n"," array([4, 3, 7]),\n"," array([4, 3, 8]),\n"," array([4, 3, 9])]"]},"execution_count":65,"metadata":{},"output_type":"execute_result"}],"source":["nums_list"]},{"cell_type":"code","execution_count":98,"metadata":{"executionInfo":{"elapsed":51171,"status":"ok","timestamp":1653665031587,"user":{"displayName":"Tamir Hemo","userId":"01253531569268226149"},"user_tz":420},"id":"WKePNCmKCfqv"},"outputs":[],"source":["# \n","components = [100 if i>1 else 30 for i in range(num_of_exps)]\n","base_clf = RandomForestClassifier(random_state=42)\n","#clf_list = [make_pipeline(StandardScaler(), PCA(n_components = n),base_clf) for n in components]\n","clf_list = [make_pipeline(StandardScaler(), base_clf) for n in components]\n","\n","cv_scores = [calculate_cv_scores(clf_list[i], X_list[i], y_list[i], 10)\n","              for i in range(num_of_exps)]"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[{"data":{"text/plain":["array([0., 0., 0., 0., 0.])"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["np.zeros(5)"]},{"cell_type":"code","execution_count":95,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":288,"status":"ok","timestamp":1653665040100,"user":{"displayName":"Tamir Hemo","userId":"01253531569268226149"},"user_tz":420},"id":"qfp6KdyjGTfb","outputId":"43f394d2-bb63-47ce-86df-8da0a1877386"},"outputs":[],"source":["experiment_name = 'lagrangian_aug'\n","model_type = '/cv_scores_RF.npy'\n","scors_arr = np.zeros((num_of_exps, 2))\n","for i, scores in enumerate(cv_scores):\n","  mean = scores.mean()\n","  std = scores.std()\n","  scors_arr[i] = np.array([mean, std])\n","  #print(experiment_name + f'{i}, Error = {mean:.2f}' + u\"\\u00B1\" + f'{std:.2f} \\n')\n","\n","np.save('Experiments/NCI1/'+experiment_name+model_type, scors_arr)"]},{"cell_type":"code","execution_count":96,"metadata":{},"outputs":[{"data":{"text/plain":["0.6209245742092457"]},"execution_count":96,"metadata":{},"output_type":"execute_result"}],"source":["z = np.load('Experiments/NCI1/'+experiment_name+model_type)\n","z.max()"]},{"cell_type":"code","execution_count":75,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1564,"status":"ok","timestamp":1653665071069,"user":{"displayName":"Tamir Hemo","userId":"01253531569268226149"},"user_tz":420},"id":"Nt2qqWU8CiXl","outputId":"7b71c2ae-77f8-4a67-84f6-b8eeb31d1f25"},"outputs":[{"data":{"text/plain":["{'train_score': 0.9990266060999351, 'test_score': 0.806420233463035}"]},"execution_count":75,"metadata":{},"output_type":"execute_result"}],"source":["expr = 6\n","clf = clf_list[expr]\n","X = X_list[expr]\n","y = y_list[expr]\n","calculate_single_split_score(clf, X, y, cv_num = 10, random_state = 25)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fqGls3GLkwbT"},"outputs":[],"source":["#pca = PCA(n_components = 100)\n","#pca.fit(X_train, y_train)\n","\n","#X_train_new = pca.transform(X_train)\n","#X_test_new = pca.transform(X_test)\n","\n","#clf = make_pipeline(StandardScaler(), SVC(random_state=42, C = 100))\n","#clf = make_pipeline(StandardScaler(), RandomForestClassifier(random_state=42))\n","# fit model\n","#clf.fit(X_train_new, y_train)\n","\n","#train_score = clf.score(X_train_new, y_train)\n","#test_score = clf.score(X_test_new, y_test)"]},{"cell_type":"code","execution_count":55,"metadata":{},"outputs":[],"source":["dtry = np.array({'1':torch.zeros(3), '2':2}, dtype = object)\n","np.save('trying.npy', dtry)"]},{"cell_type":"code","execution_count":56,"metadata":{},"outputs":[{"data":{"text/plain":["array({'1': tensor([0., 0., 0.]), '2': 2}, dtype=object)"]},"execution_count":56,"metadata":{},"output_type":"execute_result"}],"source":["import numpy as np\n","numsarr = np.load('pattern_graphs/PROTEINS/lagrangian_aug/.npy', allow_pickle=True)\n","s"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"data":{"text/plain":["tensor([[0, 1],\n","        [0, 2],\n","        [1, 0],\n","        [1, 2],\n","        [2, 0],\n","        [2, 1]])"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["import networkx as nx\n","sm_graph = uts.from_networkx(nx.complete_graph(3))\n","sm_graph.edge_index.t()"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["sm_graph.edge_attr = torch.tensor([[1], [2], [1], [3], [2], [3]])"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"data":{"text/plain":["tensor([[1],\n","        [2],\n","        [1],\n","        [3],\n","        [2],\n","        [3]])"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["sm_graph.edge_attr"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"experiments_colab_notebook.ipynb","provenance":[],"toc_visible":true},"interpreter":{"hash":"aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"},"kernelspec":{"display_name":"Python 3.10.4 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"}},"nbformat":4,"nbformat_minor":0}
