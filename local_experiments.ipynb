{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.transforms import BaseTransform\n",
    "from torch_geometric.datasets import TUDataset, ZINC\n",
    "from ogb.graphproppred import PygGraphPropPredDataset\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graph_encoding.encoding as encoding\n",
    "import networkx as nx\n",
    "import torch_geometric.utils as uts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment: ogbg-molhiv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ogb.graphproppred.mol_encoder import AtomEncoder, BondEncoder\n",
    "emb_dim = 10\n",
    "atom_encoder = AtomEncoder(emb_dim)\n",
    "bond_encoder = BondEncoder(emb_dim)\n",
    "\n",
    "class atom_transform(BaseTransform):\n",
    "  def __call__(self, data):\n",
    "    newdata = data.clone()\n",
    "    newdata.x = atom_encoder(data.x)\n",
    "    return newdata\n",
    "\n",
    "transform = atom_transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset: PygGraphPropPredDataset(41127):\n",
      "====================\n",
      "Number of graphs: 41127\n",
      "Number of features: 10\n",
      "Number of classes: 2\n",
      "\n",
      "Data(edge_index=[2, 40], edge_attr=[40, 3], x=[19, 10], y=[1, 1], num_nodes=19)\n",
      "=============================================================\n"
     ]
    }
   ],
   "source": [
    "dataset = PygGraphPropPredDataset(name = \"ogbg-molhiv\", root = 'dataset/', transform = transform)\n",
    "\n",
    "print()\n",
    "print(f'Dataset: {dataset}:')\n",
    "print('====================')\n",
    "print(f'Number of graphs: {len(dataset)}')\n",
    "print(f'Number of features: {dataset.num_features}')\n",
    "print(f'Number of classes: {dataset.num_classes}')\n",
    "\n",
    "data = dataset[0]  # Get the first graph object.\n",
    "\n",
    "print()\n",
    "print(data)\n",
    "print('=============================================================')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Expected input format of Evaluator for ogbg-molhiv\n",
      "{'y_true': y_true, 'y_pred': y_pred}\n",
      "- y_true: numpy ndarray or torch tensor of shape (num_graph, num_task)\n",
      "- y_pred: numpy ndarray or torch tensor of shape (num_graph, num_task)\n",
      "where y_pred stores score values (for computing AUC score),\n",
      "num_task is 1, and each row corresponds to one graph.\n",
      "nan values in y_true are ignored during evaluation.\n",
      "\n",
      "==== Expected output format of Evaluator for ogbg-molhiv\n",
      "{'rocauc': rocauc}\n",
      "- rocauc (float): ROC-AUC score averaged across 1 task(s)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from ogb.graphproppred import Evaluator\n",
    "\n",
    "evaluator = Evaluator(name = 'ogbg-molhiv')\n",
    "print(evaluator.expected_input_format) \n",
    "print(evaluator.expected_output_format)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the given train-test split\n",
    "\n",
    "split_idx = dataset.get_idx_split()\n",
    "\n",
    "train_idx = split_idx[\"train\"]\n",
    "valid_idx = split_idx[\"valid\"]\n",
    "test_idx  = split_idx[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load different data\n",
    "\n",
    "X = np.load('Experiments/ogbg-molhiv/experiment_1_X.npy')\n",
    "y = np.load('Experiments/ogbg-molhiv/experiment_1_y.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((41127, 20), (41127,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train , y_train = X[train_idx], y[train_idx]\n",
    "X_valid , y_valid = X[valid_idx], y[valid_idx]\n",
    "X_test , y_test = X[test_idx], y[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up experiment\n",
    "C_array = [10**3, 10**2, 10** 1, 10**0, 10**-1, 10**-2, 10**-3]\n",
    "\n",
    "max_score = 0\n",
    "C_max = 0\n",
    "for C in C_array:\n",
    "    clf = make_pipeline(StandardScaler(), SVC(kernel='rbf', C = 1, probability = True, random_state=42))\n",
    "    # fit model\n",
    "    clf.fit(X_train, y_train)\n",
    "    # Calculate predictions \n",
    "    y_valid_pred = clf.predict_proba(X_valid)\n",
    "\n",
    "    y_pred_valid = y_valid_pred[:,1].reshape(4113,1)\n",
    "    y_true_valid = y_valid.reshape(4113,1)\n",
    "\n",
    "    input_valid_dict = {'y_true': y_true_valid, 'y_pred': y_pred_valid}\n",
    "    valid_score = evaluator.eval(input_valid_dict)['rocauc']\n",
    "\n",
    "    if valid_score > max_score:\n",
    "        max_score = valid_score\n",
    "        C_max = C\n",
    "        \n",
    "max_score, C_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6335618687112535"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate test score\n",
    "# Calculate predictions \n",
    "clf = make_pipeline(StandardScaler(), SVC(kernel='rbf', C = 100, probability = True, random_state=42))\n",
    "# fit model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_test_pred = clf.predict_proba(X_test)\n",
    "\n",
    "y_pred_test = y_test_pred[:,1].reshape(4113,1)\n",
    "y_true_test = y_test.reshape(4113,1)\n",
    "\n",
    "input_test_dict = {'y_true': y_true_test, 'y_pred': y_pred_test}\n",
    "test_score = evaluator.eval(input_test_dict)['rocauc']\n",
    "\n",
    "test_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8696038451507128"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate train auroc\n",
    "\n",
    "y_train_pred = clf.predict_proba(X_train)\n",
    "\n",
    "y_pred_train = y_train_pred[:,1].reshape(32901,1)\n",
    "y_true_train = y_train.reshape(32901,1)\n",
    "\n",
    "input_train_dict = {'y_true': y_true_train, 'y_pred': y_pred_train}\n",
    "test_score = evaluator.eval(input_train_dict)['rocauc']\n",
    "\n",
    "test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_0 = np.load('Experiments/PROTEINS/experiment_0_X.npy')\n",
    "#y_0 = np.load('Experiments/PROTEINS/experiment_0_y.npy')\n",
    "#nums_0 = np.load('Experiments/PROTEINS/experiment_0_nums.npy')\n",
    "\n",
    "#nums_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graph_encoding.encoding as encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_data = [np.load(f'Experiments/ogbg-molhiv/SVM_data_{i}.npy') for i in range(12)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([8.33128491e-01, 5.96948570e-01, 6.07090804e-01, 1.00000000e+03]),\n",
       " array([9.19120766e-01, 5.89663763e-01, 6.03737997e-01, 1.00000000e+03]),\n",
       " array([9.52165367e-01, 6.32547944e-01, 5.99668700e-01, 1.00000000e+03]),\n",
       " array([9.74501161e-01, 6.28011356e-01, 6.29736797e-01, 1.00000000e+03]),\n",
       " array([7.61285118e-01, 6.33851561e-01, 6.27066799e-01, 1.00000000e+03]),\n",
       " array([8.85788440e-01, 6.43295545e-01, 6.29249951e-01, 1.00000000e+03]),\n",
       " array([9.37832118e-01, 6.36951274e-01, 6.05789487e-01, 1.00000000e+03]),\n",
       " array([9.69677268e-01, 6.17470403e-01, 6.38392857e-01, 1.00000000e+03]),\n",
       " array([7.45167444e-01, 6.16630294e-01, 6.04240153e-01, 1.00000000e+03]),\n",
       " array([8.70003641e-01, 6.39498638e-01, 6.16827724e-01, 1.00000000e+03]),\n",
       " array([9.25101601e-01, 6.45779177e-01, 6.08529909e-01, 1.00000000e+03]),\n",
       " array([9.64920425e-01, 6.09311690e-01, 6.41053669e-01, 1.00000000e+03])]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_data = [np.load(f'Experiments/ogbg-molhiv/random_forest_scores_{i}.npy') for i in range(12)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6, 4, 1])"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = torch.tensor([[1,2,3], [3,0,1], [1,0,0]])\n",
    "torch.sum(r, dim =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[1, 0], [1, 1], [1, 0], [1, 1], [1, 0]])\n",
    "sumx =  torch.tensor([[1], [2], [1], [2], [1]])\n",
    "\n",
    "6 + 2* 6+ 4\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nx.draw(nx.complete_graph(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 12], num_nodes=4)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F = encoding.testGraph(nx.complete_graph(1), graph_name='c_3')\n",
    "G = uts.from_networkx(nx.complete_graph(4))\n",
    "\n",
    "G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{<graph_encoding.encoding.testGraph at 0x136dc9990>}"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_data = encoding.grandEmbedding(G)\n",
    "encoded_data.clear_all_testgraphs()\n",
    "encoded_data.add(F)\n",
    "encoded_data.testgraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([], size=(0, 2), dtype=torch.int64)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_list = list(encoded_data.subIso(F))\n",
    "converts = lambda x: dict_list[x]\n",
    "maps = [(lambda x: dict[x]) for dict in dict_list]\n",
    "\n",
    "test_edge_list = F.pyg_graph().edge_index.t()\n",
    "test_edge_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([24, 6, 2])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_edge_tensor = torch.stack([test_edge_list.clone().apply_(lambda x: dict[x]) for dict in dict_list])\n",
    "test_edge_tensor.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 0, 0],\n",
       "         [1, 1, 1]],\n",
       "\n",
       "        [[1, 0, 0],\n",
       "         [1, 1, 0]],\n",
       "\n",
       "        [[1, 1, 1],\n",
       "         [1, 0, 0]],\n",
       "\n",
       "        [[1, 1, 1],\n",
       "         [1, 1, 0]],\n",
       "\n",
       "        [[1, 1, 0],\n",
       "         [1, 0, 0]],\n",
       "\n",
       "        [[1, 1, 0],\n",
       "         [1, 1, 1]]])"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_ten = torch.tensor([[1,0,0], [1,1,1], [1,1,0], [1,1,1]] )\n",
    "\n",
    "x_all = x_ten[test_edge_tensor]\n",
    "\n",
    "x_all[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([24, 3])"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = torch.prod(x_all, dim=-2)\n",
    "#result.size()\n",
    "\n",
    "suming = torch.sum(result, dim = -2)\n",
    "suming.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = dict()\n",
    "len(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoded_data.clear_all_testgraphs()\n",
    "encoded_data.add_trees(stop = 3)\n",
    "tree = list(encoded_data.testgraphs)[0]\n",
    "\n",
    "tree.draw()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
